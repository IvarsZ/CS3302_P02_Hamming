\documentclass{article}

\usepackage{fixltx2e}
\usepackage{amsfonts}
\usepackage{amsmath}

\title{Hamming Codes and Error Correction}
\author{100014525}
\date{November 2013}

\begin{document}
\maketitle

\section{Introduction}

A Hamming code $(2^r - 1, 2^r - r - 1, 3)$ for $r \in \mathbb{N}, r >= 2$ has a higher information rate when r is larger, but the chance of a non-correctable error is also higher. Thus this practical examines the trade-offs between these for different values of r and different probabilities p that any given bit in the channel is flipped.

Another alternative of error detection is considered where the information is resent through the channel when an error is detected. The effective information rate is the information rate divided by how many times the code word was resent. In this case the effective information rate is used instead to determine code's efficiency. Note that this assumes that the cost of requests to resend is negligible.

The program constructs a Hamming code for a given r to both encode and decode code words. It is able to detect errors of weight up to 3 and correct errors of weight 1. To do the experiments the program constructs Hamming codes for different values of r and then examines the information rate against the reliability of the code for channels of different error probability values p in both scenarios mentioned above.

Extensions done:
\begin{itemize}
	\item The obtained results are presented using insightful visual representations.
	\item A mathematical analysis that predicts the outcomes of the experiments based on r and p is provided.
	\item Extended and punctured codes are implemented and considered in the analysis.
\end{itemize}

DESCRIBE THE EXTENSIONS HERE OR ABOVE? MAYBE LATER IN THE REPORT?

\subsection{How to build and run}
\begin{itemize}
	\item Build using maven by executing the command: mvn package.
	\item Run by executing the command: TODO.
\end{itemize}

\section{Hamming codes}

Let $n=2^r-1$ and $m=2^r-r-1$. To construct a Hamming code $(n, m, 3)$ generate its parity check matrix $H$ in normal form. Arrange all n non-zero words of length $r$ as rows of $H$ in such a way that it has the $r \times r$ identity matrix $I'$ at the bottom of it. So

\begin{center}
$
H =
\begin{pmatrix}
  X \\
  I'
\end{pmatrix}
$
\end{center}
where $X$ consists of the words with weight at least two.


Then get the $m \times n$ generator matrix $G$ by using
$
G =
\begin{pmatrix}
  I & X
\end{pmatrix}
$
where $I$ is the $m \times m$ identity matrix. Next compute for each possible error $e$ (source word of weight at most 1) its syndrome $s=eH$ and map from syndromes to errors.

Now we are ready to do encoding and decoding. To encode a source word of length $m$ multiply it by $G$. To decode a word $v$ compute its syndrome $vH$, look up the corresponding error and compute $u=v+e$. Then the first $m$ symbols of $u$ form the decoded word.


\section{Design and implementation}

TODO

The map from syndromes to errors isn't actually stored. Notice that if the i-th entry in the error vector is 1, then the corresponding syndrome is the i-th row of parity check matrix H. Therefore we arrange the rows of H in a specific order. Associate a row of H with the integer it forms when converted from the binary form to decimal, then the rows of weight 1 are powers 2, while the rest are not powers of 2. The rows of weight 1 form the identity matrix at the bottom and are arranged in descending order. The rows of higher weight are at the top and are arranged in ascending order. Now when mapping a syndrome to an error it is converted to decimal form d and its row number (?) is found. If it is a power 2 then the row number is $n - log_2(d) - 1$, otherwise it is $errorIndex - \lfloor(log_2(d))\rfloor - 2$.
 to determine the bit that is flipped by the error.
 
 Does information source matters?

\end{document}
